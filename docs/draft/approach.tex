\section{Paths Searching Approaches}
\label{sec:approach}

In the Blue Gene/Q supercomputer, data is routed throught its interconnect network using default routing algorithms. The default routing algorithms are proved to be well-performed in many communication patterns \cite{Chen:BGQ}. However, for certain communication patterns (shown later in this paper), they results in poor performance due to unbalanced networking load on physical links, in which some links serve significant larger amount of data transferred through than other links. This is because the default algorithms use a single path to transfer data between any two nodes in the supercomputer. In addition, the data traverses along the path on certain links regardless of the load on other links. Thus, some links are overloaded while other links have less data or may even be idle. The overloaded links become bottleneck in data movement. Balancing the load on the physical links removes the bottleneck and thus improves the data transfer throughtput. In order to balance the load, we need to involve more physical links in data transfer, search for more paths between source and destination nodes and assign load appropriately for each path.

Given a set of source nodes and another set of destination nodes together with data sizes to be transferred from sources to destinations, searching for paths that result in high throughput is challenging due to a very large number of paths available in search space. This leads to significant amount of time spending on searching for paths, calculating and balancing load in involving links. We reduce the search time while maintaining good quality of chosen paths by doing the follows:
\begin{itemize}
\item We simplify the load on a link by substituting the actual load i.e the amount of data passing throught the link by path load i.e. number paths that share the link. This is acceptable when the data amounts assigned on paths are similar. 
\item We prune the search space by:
\begin{itemize}
\item Appling load path constrant and number of hops constraint while searching for paths.
\item Performing 2-step search. In the first step, we search for a number of shortest paths without any constraints. From the set of shortest paths, we apply constraints or use optimization methods to search for final set of paths in the second step. 
\end{itemize}
\end{itemize}

In this paper, we propose three approaches aiming for balancing load on physical links: two heuristic algorithms and one model-based optimization approach. In the first approach, we use the path load instead of actual data load and apply maximum load and maximum hop constraints while searching for paths. In the second and third approaches, we use 2-step search. At the first step, we use Yen's algorithm \cite{Yen:Kpath} to search for a set of shortest paths. For the second step, in the second approach, we use maximum load path constraint to prune the search space, while in the third approach, we use an optimization model with solvers to search for final paths. In this paper, we use Yen's algorithm, but any algorithms searches for K shortest paths should work as well.

In order to search for paths, we model the interconnect network as a graph. Each compute node is modeled as a vertex and each physical link is modeled as an edge. The bandwidth of a physical link is modeled as its corresponding edge's capacity. The need of data movement from source nodes to destination nodes is modeled as data movement from source vertices to destination vertices. The problem now becomes searching for paths to move data from source vertices to destination vertices to minimize tranfer time. The next subsections explain our approaches in detail.

\subsection{Heuristic I - Breadth First Search Based Approach}

Our first heuristic approach is based on breadth first search. In this approach, we search for paths between each pair of source and destination using breadth first search and min heap. While we use breadth first search to explore paths, we use the min heap to keep all exploring paths and extract the min path (the order of paths in the min heap is decided by its heapify function). The exploration starts from the sources. From each source, we add 1-hop paths to its neighbors to the min heap. A path in the min heap which starts from a source but has not yet reached to its destination is called an \textit{exploring path}. As we explore we extract the min path, form and add more \textit{exploring paths} to the min heap. Any paths that reaches to its destination is saved for later use. Any paths that is longer than maximum allowed number of hops is removed. The algorithm finishes when the min heap is empty. The algorithm is described in \textbf{Algorithm \ref{alg:h1}}. We explain details of the algorithms in the follows.

We use \textit{struct arc} to present an arc in the graph. A path is set of \textit{arc}s. An arc can be used by zero or many paths. The number of paths uses an arc is called \textit{load} of the arc. Each path has a \textit{maxload} which is the maximum value of \textit{load}s of arcs of the path. The \textit{min\_heap} is a heap of paths. It uses \textit{heap\_compare} function to maintain the order of paths in the heap (heapify). The \textit{heap\_compare} compare two paths based on their number of hops and \textit{maxload}.

\begin{algorithm}[!htp]
\textbf{Input:} Set of pairs of source-destination (\textit{s$_i$, d$_i$}). Number of nodes \textit{n}. Graph of nodes. \\
\textbf{Output:} Set of paths: one path for a pair of source-destination \\

Structures:
    \begin{algorithmic}
        \State struct arc \{int u, int v\};
        \State struct path \{set of arcs, int maxload\};
        \State min\_heap \{set of paths\}
    \end{algorithmic}

min\_heap's element comparison function:
    \begin{algorithmic}
        \Function{heap\_compare} {path p1, path p2}
            \If {one path has lower load}
                \State choose the one with lower load.
            \ElsIf {Two paths have equal loads}
                \State Choose the one with smaller number of hops.
            \EndIf
        \EndFunction
    \end{algorithmic}

Init:
    \begin{algorithmic}
	\State min\_heap$<$struct path$>$ \textit{exploring\_paths} = $\varnothing$;
	\State queue$<$struct path$>$ \textit{complete\_paths} = $\varnothing$;
	\State bool \textit{visisted}[\textit{n}][\textit{n}];
	\For {0 $<=$ {\it i}, \textit{j} $<$ \textit{n}} 
	    \State \textit{visited}[{\it i}][{\it j}] = false;
	\EndFor
    \end{algorithmic}
Main:

\begin{algorithmic}
    \Function {Heuristic\_search\_I}{}

    \While {exist a source \textit{s$_i$} with unvisted neighbor \textit{u}}
	\State check\_and\_add\_new\_path({\it s}$_i$, \textit{u}, null);
	\State Pick next \textit{s$_i$} in the sources
    \EndWhile

    \While {(\textit{exploring\_paths} != $\varnothing$)}
	\State path \textit{p} = \textit{exploring\_paths}.extract\_min();
	\State {\it u} = last vertex in the path {\it p};
	\For {each neighbor \textit{v} of \textit{u}}
	    \State check\_and\_add\_new\_path({\it u}, \textit{v}, {\it p});
	\EndFor
    \EndWhile

    \EndFunction
\\
    \Function{check\_and\_add\_new\_path}{int \textit{u}, int \textit{v}, path {\it op}}
	\If {(!{\it visited}[{\it u}][{\it v}])}
	    \State create a path \textit{np} = {\it op}
	    \State add arc $<$\textit{u}, \textit{v}$>$ to \textit{np}
	    \State enqueue \textit{np} to \textit{exploring\_paths}
	    \If {{\it v} is one of the destinations of \textit{s$_i$} of \textit{np}}
	        \State enqueue \textit{np} to \textit{complete\_paths}
		\State {Update load of all edges and \textit{maxload} of paths in \textit{exploring paths} as \textit{np} is used}
            \EndIf
	    \State {\it visited}[\textit{u}][\textit{v}] = true;
	\EndIf
    \EndFunction
\end{algorithmic}

\caption{Heuristic Alg 1: Exploring all paths without constraints}
\label{alg:h1}

\end{algorithm}

The \textbf{Algorithm \ref{alg:h1}} can be divided into 2 parts. In the first part, which is in the first \textbf{while} loop of the function Heuristic\_search\_I, we start at every source and add 1-hop paths to \textit{exploring\_paths} queue. Those paths are the paths from sources to their neighbors. 

In the second part, which is the second \textbf{while} loop of the function Heuristic\_search\_I, we extract the min path \textit{p} from the min heap \textit{exploring\_paths}. From the last added vertex \textit{u} of \textit{p}, we exploring all edges from it to it neighbors and add a new path \textit{np} = \textit{p} + \textit{edge} for each newly explored edge. If any of its neighbors is final destination of source \textit{s$_i$}, we then add \textit{np} into \textit{complete\_paths}. When we add a new path to min heap \textit{exploring\_paths} we also update an table that keeps the loads of all physical links. The load table is used by heapify function to compare \textit{maxload} of paths. We continue the work until all the paths are explored.

Time complexity: The graph has V vertices and E edges. We have K pairs of (source, destinatinon), each source has at most D neighborhoods, then the time complexity of the \textbf{Algorithm \ref{alg:h1}} is $O$(K * D + K * ($|$V$|$ + $|$E$|$) * log($|$V$|$ + $|$E$|$)). The time complexity is breakdown as following:
\begin{itemize}
\item First part: we have K pairs hence K sources, for each source we discover its D neighbors, thus time will be $O$(K*D).
\item Second part: For this part, we get a path out of \textit{exploring\_paths}, create new paths by exploring its neighbors that are not visited by its source and add the new paths back to \textit{exploring\_paths}. For each sources, every vertex and every edge can be visited in the worst case, the time complexity would be $O$($|$V$|$ + $|$E$|$) minus to the vertices and edges visited by the first part. At each source, we also need heapify as we add new paths. The time complexity for heapifying is log($|$V$|$ + $|$E$|$)) as we have $O$($|$V$|$ + $|$E$|$) paths in the heap. Since we have K sources, the time complexity is $O$(K * ($|$V$|$ + $|$E$|$) * log($|$V$|$ + $|$E$|$))).
\end{itemize}

\subsection{Heuristic II - Path-based Approach}

\begin{algorithm}[!htp]
\textbf{Input:} Set of pairs of source-destination (\textit{s$_i$, d$_i$}). Number of nodes \textit{n}. Graph of nodes. Number of shortest path \textit{k}\\
\textbf{Output:} Set of paths: \textit{k} paths for a pair of source-destination\\
Structures:
    \begin{algorithmic}
        \State struct arc \{int u, int v\};
        \State struct path \{set of arcs, int maxload\};
    \end{algorithmic}

Init:
    \begin{algorithmic}
        \State queue$<$struct path$>$ \textit{complete\_paths};
    \end{algorithmic}
Main:
\begin{algorithmic}
    \Function {Heuristic\_search\_II}{}
	\For {each pair of source-dest (\textit{s$_i$}, \textit{s$_i$})}
	    \While{less than k paths discovered || still have paths to discover}
		\State Use Yen's algorithm to search for the shortest path \textit{p}.
		\State Check if adding \textit{p} make the current load over \textit{maxload}.
		\State If not, add \textit{p} into \textit{complete\_paths}
	    \EndWhile
	\EndFor
    \EndFunction
\end{algorithmic}

\caption{Heuristic Alg 2: k shortest paths}
\label{alg:h2}

\end{algorithm}

In the \textbf{Algorithm \ref{alg:h3}}, we use Yen's algorithm to search for k shortest paths between \textit{s$_i$, d$_i$}.

In Agorithm 1 and 2, we aim on balancing the number of paths using physical link. However, we do not consider the actual amount of data transferred on each path. If multiple paths are found, the data is equally split among the paths. To gain better performance, we determine the amount of data to be transferred on each path by using a mathematical model to search for the amount of data to be transferred on each path. The approach takes a number of given paths and amount of data between 2 vertices and use solvers to search for the amount of data on each path. The detail is described as follows.

\subsection{Path-based Model Optimization}

How do we come up with the model?

Here is the model with its description below.

\begingroup
\fontsize{9pt}{9pt}\selectfont

\begin{verbatim}

set Nodes;
set Arcs within Nodes cross Nodes;

set Jobs;
set Paths{Jobs};
set Path_Arcs{job in Jobs, p in Paths[job]} 
    within Arcs;

param Capacity{Arcs} >= 0 default Infinity;
param Demand {Jobs} default 0;

var Flow {job in Jobs, Paths[job]} >= 0;
var Z >= 0;

maximize obj: Z;

subject to

demand {job in Jobs}: sum {p in Paths[job]} 
	Flow[job,p] = Demand[job]*Z;

capacity {(i,j) in Arcs}:
  sum {job in Jobs, p in Paths[job]: 
    (i,j) in = Path_Arcs[job,p]} Flow[job,p] 
		<= Capacity[i,j];

\end{verbatim}

\endgroup

Model explanation:
\begin{itemize}
\item sets: we have 5 sets: \textit{Nodes}, \textit{Arcs}, \textit{OD}, \textit{Paths} and \textit{Path\_Arcs}. \textit{JobID}: is the set of transfers from sources to destinations. Each job is represented by a tuple (id, source, destination, demand (total data size to transfer)).
\item params: {\it Capacity}: capacity of each arc; {\it Demand}: amount of data to be transferred in each job between a pair of orgin and destination.
\item vars: \textit{Flow}: total flow of each job on each arc; \textit{Z}: is reversed of total time; \textit{total\_flow} total flow of all jobs going through an arc.
\item objective function: we want to minimize the time or maximize its reversed value i.e. maximize \textit{Z}.
\item constraints(subject to): \textit{zero\_flow}: total flow through a source is total going out of that source, total flow going through a destination is total flow going in that destination, for other nodes that total is 0; \textit{capacity}: total flow on an arc is less than its capacity.
\end{itemize}

We feed the model to solvers and get the paths with given proportional bandwidth. Based on that, we can decide how much data we can transfer alogn each path.

So far, we have presented different algorithms/approaches. Each has its own use case scenario. The Table \ref{tbl:approaches} describes the situation when to use each of them. 

\begin{table}[h]

\begin{center}
    \begin{tabular}{ | p{0.8cm} | p{2cm} | p{2cm} | p{2cm} |}
    \hline
     & BFS-based &  \multicolumn{2}{ c| }{Path-based} \\ \hline
     & Heuristics 1 & Heuristics 2 & Optimization Model \\ \hline
    Time Complexity & $O$(K * ($|$V$|$ + $|$E$|$)) & $O$(K * (Time complexity of the algrithms used to get k shortest paths)) & $O$(K * (Time complexity of the algrithms used to get k shortest paths) + Solving time) \\ \hline
    When to use & Very dense communication & Sparse comminication &  Medium dense where proportional throughtput can be gained \\
    \hline
    \end{tabular}

    \caption{Approaches: time complexity and usage}
    \label{tbl:approaches}

\end{center}
\end{table}

We realize algoirthms and other work in a framework named OPTIQ.
